load("~/Dropbox/Projects_Writeup&Ref/David_Dunson/OutlierDetection/correlation_result.RData")
View(test.result)
options(timeout = 300)
torch::install_torch(reinstall = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
library(torch)
library(dplyr)
# Prepare Data
# Convert matrix to a Torch Tensor and normalize to 0-1 range
x_mat <- scale(sc_flat_clean)
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
# Load Raw Structural Data
# This is the 68x68x1065 Tensor
struct_raw <- readMat("Data/SC/HCP_cortical_DesikanAtlas_SC.mat")
sc_tensor  <- struct_raw$hcp.sc.count
sc_ids     <- as.vector(struct_raw$all.id)
n_subs <- length(sc_ids)
# There are 68x67/2 = 2278 unique connections in a symmetric matrix
n_feats <- 68 * 67 / 2
# Flatten the 3D Tensor into a 2D Matrix (Subjects x Connections)
# We only take the upper triangle to avoid duplicates
sc_flat <- matrix(NA, nrow = n_subs, ncol = n_feats)
print("Flattening Structural Data...")
for (i in 1:n_subs) {
# Extract single subject matrix
mat <- sc_tensor[,,i]
# Flatten upper triangle
sc_flat[i, ] <- mat[upper.tri(mat)]
}
# Remove Zero Variance Columns
# We calculate variance for every column
col_vars <- apply(sc_flat, 2, var)
# We identify columns where variance is 0 (Constant columns)
const_cols <- which(col_vars == 0)
print(paste("Removing", length(const_cols), "constant columns..."))
# We subset the matrix to keep only columns with variance > 0
if (length(const_cols) > 0) {
sc_flat_clean <- sc_flat[, -const_cols]
} else {
sc_flat_clean <- sc_flat
}
# Run Standard PCA
# rank. = 60 keeps only the top 60 components to match TNPCA
print("Running Structural PCA...")
sc_pca <- prcomp(sc_flat_clean, center = TRUE, scale. = TRUE, rank. = 60)
# Create Dataframe
# We name them "Raw_Struct_PC" to distinguish from the TNPCA "Struct_PC"
my_struct_df <- data.frame(Subject = sc_ids, sc_pca$x)
colnames(my_struct_df)[2:61] <- paste0("Raw_Struct_PC", 1:60)
library(R.matlab)
library(dplyr)
# --- Load Raw Functional Data ---
func_raw <- readMat("Data/FC/HCP_cortical_DesikanAtlas_FC.mat")
fc_list  <- func_raw$hcp.cortical.fc
fc_ids   <- as.vector(func_raw$subj.list)
n_subs_fc <- length(fc_ids)
n_feats <- 68 * 67 / 2
# Initialize with NA (So bad subjects just stay as NA)
fc_flat <- matrix(NA, nrow = n_subs_fc, ncol = n_feats)
print("Flattening Functional Data (with Error Checking)...")
for (i in 1:n_subs_fc) {
# Extract matrix
mat <- fc_list[[i]]
if (is.list(mat)) { mat <- mat[[1]] }
# If matrix is actually 68x68
if (all(dim(mat) == c(68, 68))) {
fc_flat[i, ] <- mat[upper.tri(mat)]
} else {
# If bad (0x0), we do nothing. The row stays as NA.
print(paste("Skipping Subject Index:", i, "- Empty/Bad Matrix"))
}
}
# --- Drop Bad Subjects ---
# We verify which rows are still NA and remove them
bad_rows <- which(is.na(fc_flat[,1]))
if (length(bad_rows) > 0) {
print(paste("Removing", length(bad_rows), "failed subjects."))
fc_flat_clean <- fc_flat[-bad_rows, ]
fc_ids_clean  <- fc_ids[-bad_rows]
} else {
fc_flat_clean <- fc_flat
fc_ids_clean  <- fc_ids
}
# --- Remove Zero Variance Columns ---
col_vars_fc <- apply(fc_flat_clean, 2, var)
const_cols_fc <- which(col_vars_fc == 0)
if (length(const_cols_fc) > 0) {
fc_flat_final <- fc_flat_clean[, -const_cols_fc]
} else {
fc_flat_final <- fc_flat_clean
}
# --- Run PCA ---
print("Running Functional PCA...")
fc_pca <- prcomp(fc_flat_final, center = TRUE, scale. = TRUE, rank. = 60)
# --- Create Dataframe ---
my_func_df <- data.frame(Subject = fc_ids_clean, fc_pca$x)
colnames(my_func_df)[2:61] <- paste0("Raw_Func_PC", 1:60)
print("Functional PCA Complete.")
write.csv(my_struct_df, "raw_struct_pca.csv")
write.csv(my_func_df, "raw_func_pca.csv")
library(torch)
library(dplyr)
# Prepare Data
# Convert matrix to a Torch Tensor and normalize to 0-1 range
x_mat <- scale(sc_flat_clean)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
torch::install_torch(reinstall = TRUE)
library(torch)
library(dplyr)
# Prepare Data
# Convert matrix to a Torch Tensor and normalize to 0-1 range
x_mat <- scale(sc_flat_clean)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
library(torch)
install_torch(reinstall = TRUE)
# Diagnostic script
print("R version:")
print(version$version.string)
print("Installed packages:")
print(installed.packages()[, "Package"])
print("Try loading torch:")
tryCatch({
library(torch)
print("Torch loaded successfully")
print(paste("Torch installed:", torch_is_installed()))
print(paste("Lantern loaded:", torch_is_loaded()))
}, error = function(e) {
print(paste("Error loading torch:", e$message))
})
# Diagnostic script
print("R version:")
print(version$version.string)
print("Installed packages:")
print(installed.packages()[, "Package"])
print("Try loading torch:")
tryCatch({
library(torch)
print("Torch loaded successfully")
print(paste("Torch installed:", torch_is_installed()))
print(paste("Lantern loaded:", torch_is_loaded()))
}, error = function(e) {
print(paste("Error loading torch:", e$message))
})
# Torch package is installed but Lantern backend isn't
library(torch)
# Install the Lantern backend
install_torch()
# After installation, verify it worked:
torch_is_installed()  # Should return TRUE
torch_is_loaded()     # Should return TRUE
# Remove everything completely
remove.packages("torch")
# Clear all torch-related directories
unlink("~/.torch", recursive = TRUE, force = TRUE)
unlink("~/.cache/torch", recursive = TRUE, force = TRUE)
unlink(file.path(R.home(), "library", "torch"), recursive = TRUE, force = TRUE)
# Restart R Session (Session -> Restart R in RStudio)
# Then reinstall:
install.packages("torch")
library(torch)
install_torch()
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
install.packages("torch")
library(torch)
install.packages("torch")
install_torch()
Sys.setenv(PATH = paste0(
normalizePath(file.path(torch::lantern_install_path(), "lib")),
";",
Sys.getenv("PATH")
))
# Remove everything
remove.packages("torch")
unlink("~/.torch", recursive = TRUE, force = TRUE)
unlink("~/.cache/torch", recursive = TRUE, force = TRUE)
# Restart R session (Session -> Restart R in RStudio)
# Now reinstall with manual path
install.packages("torch")
# Set environment BEFORE loading torch
Sys.setenv(TORCH_HOME = "C:/torch")
Sys.setenv(TORCH_INSTALL = "1")
library(torch)
install_torch()
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
install.packages("torch")
# Set environment BEFORE loading torch
Sys.setenv(TORCH_HOME = "C:/torch")
Sys.setenv(TORCH_INSTALL = "1")
library(torch)
install.packages("torch")
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
remove.packages("torch")
unlink("~/.torch", recursive = TRUE, force = TRUE)
unlink("~/.cache/torch", recursive = TRUE, force = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
# Now reinstall with manual path
install.packages("torch")
# Set environment BEFORE loading torch
Sys.setenv(TORCH_HOME = "C:/torch")
Sys.setenv(TORCH_INSTALL = "1")
library(torch)
install_torch()
Sys.unsetenv("TORCH_HOME")
# Now install torch
library(torch)
install_torch()
Sys.unsetenv("TORCH_HOME")
# Now install torch
library(torch)
install_torch()
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
library(torch)
# Test immediately
x <- torch_tensor(1:3)
library(torch)
library(dplyr)
# Prepare Data
# Convert matrix to a Torch Tensor and normalize to 0-1 range
x_mat <- scale(sc_flat_clean)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
torch::install_torch()
torch::install_torch()
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
library(torch)
x_mat <- matrix(rnorm(100), nrow = 10, ncol = 10)
knitr::opts_chunk$set(echo = TRUE)
library(R.matlab)
library(tidyverse)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
x_mat <- matrix(rnorm(100), nrow = 10, ncol = 10)
x_mat <- matrix(rnorm(100), nrow = 10, ncol = 10)
x_tensor <- torch_tensor(x_mat, dtype = torch_float())
